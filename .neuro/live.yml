kind: live
title: mlops-ideal-demo

defaults:
  life_span: 1d

images:
  train:
    ref: image:/$[[ project.owner ]]/$[[ flow.project_id ]]:v1
    dockerfile: $[[ flow.workspace ]]/Dockerfile
    context: $[[ flow.workspace ]]/

volumes:
  data:
    remote: storage:/$[[ project.owner ]]/$[[ flow.project_id ]]/data
    mount: /project/data
    local: data
  code:
    remote: storage:/$[[ project.owner ]]/$[[ flow.project_id ]]/modules
    mount: /project/modules
    local: modules
  config:
    remote: storage:/$[[ project.owner ]]/$[[ flow.project_id ]]/config
    mount: /project/config
    local: config
  notebooks:
    remote: storage:/$[[ project.owner ]]/$[[ flow.project_id ]]/notebooks
    mount: /project/notebooks
    local: notebooks
  results:
    remote: storage:/$[[ project.owner ]]/$[[ flow.project_id ]]/results
    mount: /project/results
    local: results
  project:
    remote: storage:/$[[ project.owner ]]/$[[ flow.project_id ]]
    mount: /project
    local: .
  mlflow_artifacts:
    remote: storage:/$[[ project.owner ]]/$[[ flow.project_id ]]/mlflow_artifacts
    mount: /project/mlflow_artifacts

jobs:
  remote_debug:
    action: gh:neuro-actions/remote_debug@v1.0.0
    args:
      image: $[[ images.train.ref ]]
      volumes_data_remote: $[[ volumes.data.remote ]]
      volumes_code_remote: $[[ volumes.code.remote ]]
      volumes_config_remote: $[[ volumes.config.remote ]]
      volumes_results_remote: $[[ volumes.results.remote ]]

  train:
    image: $[[ images.train.ref ]]
    life_span: 10d
    volumes:
      - $[[ volumes.data.ref_ro ]]
      - $[[ upload(volumes.code).ref_ro ]]
      - $[[ volumes.config.ref_ro ]]
      - $[[ volumes.results.ref_rw ]]
    env:
      EXPOSE_SSH: "yes"
      PYTHONPATH: $[[ volumes.code.mount ]]
    bash: |
        cd $[[ volumes.project.mount ]]
        python -u $[[ volumes.code.mount ]]/train.py --data $[[ volumes.data.mount ]]

  multitrain:
    image: $[[ images.train.ref ]]
    detach: False
    life_span: 10d
    volumes:
      - $[[ volumes.data.ref_ro ]]
      - $[[ volumes.code.ref_ro ]]
      - $[[ volumes.config.ref_ro ]]
      - $[[ volumes.results.ref_rw ]]
    env:
      EXPOSE_SSH: "yes"
      PYTHONPATH: $[[ volumes.code.mount ]]
    multi: true
    bash: |
        cd $[[ volumes.project.mount ]]
        python $[[ volumes.code.mount ]]/train.py --data $[[ volumes.data.mount ]] $[[ multi.args ]]

  jupyter:
    image: ghcr.io/neuro-inc/base:v22.5.0-runtime
    preset: gpu-small-p
    http_port: 8888
    http_auth: True
    browse: True
    detach: True
    volumes:
      - $[[ volumes.data.ref_rw ]]
      - $[[ volumes.code.ref_rw ]]
      - $[[ volumes.config.ref_rw ]]
      - $[[ volumes.notebooks.ref_rw ]]
      - $[[ volumes.mlflow_artifacts.ref_rw ]]
    env:
      PYTHONPATH: /project/modules
      MLFLOW_TRACKING_URI: http://${{ inspect_job('mlflow_server').internal_hostname_named }}:5000
    cmd: >-
      jupyter notebook
        --no-browser
        --ip=0.0.0.0
        --port=8888
        --allow-root
        --NotebookApp.token=
        --notebook-dir=$[[ volumes.notebooks.mount ]]
        --NotebookApp.shutdown_no_activity_timeout=900
        --MappingKernelManager.cull_idle_timeout=7200
        --MappingKernelManager.cull_connected=True

  serve_bentoml:
    image: ${{ images.train.ref }}
    volumes:
      - ${{ volumes.mlflow_artifacts.ref_ro }}
      - $[[ volumes.code.ref_ro ]]
    env:
      MLFLOW_TRACKING_URI: http://${{ inspect_job('mlflow_server').internal_hostname_named }}:5000
      RUN_ID: ${{ params.run_id }}
    http_port: 3000
    http_auth: False
    params:
      run_id:
    bash: |
      pip install bentoml --pre
      bentoml serve ${{ volumes.code.mount }}/bento_server.py:svc --host 0.0.0.0 --port 3000
    # curl -H "Content-Type: multipart/form-data" -F 'fileobj=@Dog.jpg;type=image/jpeg' https://<job-http-url>/classify -L

  tensorboard:
    action: gh:neuro-actions/tensorboard@v1.0.0
    args:
      volumes_results_remote: $[[ volumes.results.remote ]]

  filebrowser:
    action: gh:neuro-actions/filebrowser@v1.0.1
    args:
      volumes_project_remote: $[[ volumes.project.remote ]]

  mlflow_server:
    action: gh:neuro-actions/mlflow@v1.25.2
    args:
      backend_store_uri: sqlite:///${{ volumes.mlflow_artifacts.mount }}/mlflow.db
      default_artifact_root: ${{ volumes.mlflow_artifacts.mount }}
      volumes: "${{ to_json( [volumes.mlflow_artifacts.ref_rw] ) }}"

  prepare_data:
    image: ghcr.io/neuro-inc/neuro-extras
    volumes:
      - ${{ volumes.data.ref_rw }}
    bash: |
      rm -rf ${{ volumes.data.mount }}/*
      neuro-extras data cp -x \
        https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip \
        ${{ volumes.data.mount }}/

